---
layout: draft
title: "Mixup"
date: 2020-03-22 14:49:0 +0000
comments: False
share: False
categories: cv
---

**[Improving Transformer Optimization Through Better Initialization,ICML20](http://www.cs.toronto.edu/~mvolkovs/ICML2020_tfixup.pdf)**

[code](https://github.com/layer6ai-labs/T-Fixup)

**[InstaBoost: Boosting Instance Segmentation via Probability Map Guided Copy-Pasting,ICCV19](https://arxiv.org/pdf/1908.07801.pdf)**

jittering guided by appearance consistency map

![](/imgs/instaboost.png)

**[Mixup Inference: Better Exploiting Mixup to Defend Adversarial Attacks,ICLR20](https://openreview.net/forum?id=ByxtC2VtPB)**

**[mixup: Beyond Empirical Risk Minimization,ICLR18](https://openreview.net/forum?id=r1Ddp1-Rb)**

> We use mixup and ERM to train several state-of-the-art ImageNet-2012
classification models, and report both top-1 and top-5 error rates in Table 1.

**[Manifold Mixup: Better Representations by Interpolating Hidden States<ICML19>](https://arxiv.org/pdf/1806.05236.pdf)**



**[Hide and Seek]()**
<!--

https://zhuanlan.zhihu.com/p/

-->
**[Cutout]()**

**[CutMix]()**

**[GridMask]()**










